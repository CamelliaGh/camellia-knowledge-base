# ğŸ§  All About Prompt Engineering

Prompt engineering is the practice of designing clear, structured, and efficient inputs (or *prompts*) to guide AI models like ChatGPT, Claude, or Gemini to produce the best possible outputs. While generating content with AI might seem simpleâ€”just type and waitâ€”the quality of the response often depends heavily on *how* you ask.

---

## âœ¨ Why Prompt Engineering Matters

Good prompt design:
- Ensures reliable and accurate answers.
- Helps the model stay consistent with instructions (e.g., tone, format).
- Maximizes the model's reasoning abilities.
- Reduces hallucinations or irrelevant replies.

Thereâ€™s a lot more to prompting than asking questions; we can use tailored prompts, frameworks, examples, and constraints to enhance outputs.

---

## ğŸ”§ Core Components of a Prompt

Most effective prompts include:
- **Role**: Who should the model act as? (e.g. "Act as an expert UI/UX designerâ€¦")
- **Task**: What should it do? ("Writeâ€¦", "Analyzeâ€¦", "Debugâ€¦")
- **Context**: Important background for accuracy.
- **Format**: Specify structure like tables, bullets, code blocks.
- **Examples**: (Optional) Few-shot examples to demonstrate ideal outputs.
- **Constraints**: Word limits, tone, etc.

---

## ğŸ§© Advanced Prompting Frameworks (Catalog + Examples)

Below are popular reusable **frameworks** you can copyâ€‘paste and adapt. Each includes a oneâ€‘liner and a minimal example.

### 1) **RACE** â€” *Role, Action, Context, Expectation*
- **Use when:** You need a crisp, complete instruction.
- **Template:** `Role: â€¦ | Action: â€¦ | Context: â€¦ | Expectation: â€¦`
- **Example:**  
  - Role: Senior UX writer  
  - Action: Rewrite hero copy for parenting app  
  - Context: Audience = busy moms, tone = warm, 8â€“10 words max headline  
  - Expectation: Headline + subheadline + 3 bullets + CTA

### 2) **CARE** â€” *Context, Action, Result, Example*
- **Use when:** You want to anchor with an example.
- **Template:** Provide brief context â†’ request action â†’ define desired result â†’ include 1 example.
- **Example:** Context: Library shelfâ€‘reading explainer. Action: Write a parentâ€‘friendly blurb. Result: ~90 words. Example: *â€œThink tidy shelves = faster finds.â€*

### 3) **RTF** â€” *Role, Task, Format*
- **Use when:** You need speed and consistency.
- **Template:** Role = â€¦ | Task = â€¦ | Format = â€¦
- **Example:** Role: Data analyst | Task: Summarize survey insights | Format: 5 bullets + 1 chart idea

### 4) **CRISP** â€” *Constraints, Role, Input, Steps, Product*
- **Use when:** You want explicit constraints and a step plan.
- **Template:** State constraints â†’ assign role â†’ give input â†’ ask for step plan â†’ define final product.
- **Example:** Constraints: â‰¤150 words, no jargon. Role: Career coach. Input: Candidate profile. Steps: Diagnose â†’ Advise â†’ Plan. Product: 30â€‘day plan.

### 5) **FABRIC** â€” *Facts, Ask, Boundaries, Results, Illustration, Checklist*
- **Use when:** You must avoid hallucinations and ensure sources.
- **Example:** Facts: (paste data). Ask: Draft press note. Boundaries: Only use provided facts. Results: 120â€“150 words. Illustration: 1 headline. Checklist: factual/concise/citable.

### 6) **ROSES** â€” *Role, Objective, Steps, Examples, Style*
- **Use when:** You need toneâ€‘controlled outputs with sample patterns.
- **Example:** Role: PM. Objective: Draft RICE backlog. Steps: Identify â†’ Score â†’ Rank. Examples: (2 rows). Style: concise, table.

### 7) **TAG** â€” *Task, Action, Goal*
- **Use when:** You want a singleâ€‘sentence brief.
- **Example:** Task: Summarize a 10â€‘page PDF. Action: Extract key decisions. Goal: 7 bullets for execs.

### 8) **IDEA** â€” *Intent, Data, Examples, Ask*
- **Use when:** Youâ€™re doing retrieval/RAG.
- **Example:** Intent: Compare 3 courses. Data: pasted syllabi. Examples: preferred output sample. Ask: 6â€‘row table + recommendation.

> **Tip:** Start with RTF for quick tasks. Use RACE/CRISP/FABRIC when accuracy, constraints, or auditability matter.

---

## ğŸ”µ Reasoning & Toolâ€‘Use Techniques

- **Chainâ€‘ofâ€‘Thought (CoT):** â€œThink step by step.â€ Great for math/logic/planning.
- **Selfâ€‘Ask / Stepâ€‘back:** Ask the model to list questions it needs to answer before the final output.
- **Treeâ€‘ofâ€‘Thought (ToT):** Explore multiple solution paths â†’ select best.
- **ReAct:** Alternate *reasoning* and *actions* (e.g., tool calls) in agent workflows.
- **RAG (Retrievalâ€‘Augmented Generation):** Inject external docs/snippets to ground answers.

**Miniâ€‘prompt:**  
â€œBefore answering, list the 3 most uncertain assumptions and how youâ€™ll validate each.â€

---

## ğŸ§­ Best Practices

1. Be clear & concise.  
2. Use delimiters to separate instruction sections.  
3. Define constraints explicitlyâ€”tone, format, length, exclusions.  
4. Iterate & revise; keep a prompt log.  
5. Test across different models (e.g. GPTâ€‘4 vs Claude) for consistency.  
6. Mind the context window; include only relevant material.  
7. Ask for sources or set â€˜factsâ€‘onlyâ€™ rules when accuracy matters.

---

## âœ… Prompt Engineering Checklist

- [ ] Defined objective of your prompt?  
- [ ] Included role and background context?  
- [ ] Specified format and constraints?  
- [ ] Added examples if useful?  
- [ ] Asked for reasoning if needed?  
- [ ] Verified token length?

---

## ğŸ’¡ Example Prompt (Combining Frameworks)

```
RACE+CoT
Role: Senior Technical PM
Action: Create a prioritized feature backlog for a â€œWix Events Importerâ€ MVP.
Context: One developer, one QA, 4-week sprint, 1,000-event import, Wix Velo + REST only.
Expectation: Output a Markdown table (Feature, RICE, Reason, Effort, Dependencies). Think step by step.
```

---

## ğŸ“š Further Resources

- Anthropic: Prompting & best practices
- OpenAI: Prompting guidelines & structured outputs
- PromptingGuide.ai: Technique catalog
- â€œMaterial for MkDocsâ€ (for publishing docs sites)

---

## ğŸ§± Antiâ€‘Patterns (What to Avoid)

- Overâ€‘stuffed prompts without structure.  
- Vague requests (â€œmake it betterâ€) without criteria.  
- Asking for everything at once; split into steps.  
- Relying on unstated facts; paste the source data.  
- No format constraints â†’ messy outputs.

---

## ğŸ§ª Quick Reference â€” Copyâ€‘Paste Starters

**RTF (starter):**  
`Role: â€¦ | Task: â€¦ | Format: â€¦`

**RACE (auditâ€‘friendly):**  
```
Role: â€¦
Action: â€¦
Context: â€¦
Expectation: â€¦
```

**CRISP (strict):**  
```
Constraints: â€¦
Role: â€¦
Input: â€¦
Steps: â€¦
Product: â€¦
```

**FABRIC (factâ€‘safe):**  
```
Facts: â€¦
Ask: â€¦
Boundaries: (no external info, cite all)
Results: (length/format)
Illustration: (headline/table/example)
Checklist: (accuracy, tone, structure)
```

---

## ğŸ Summary

Prompt engineering is a toolbox: **frameworks** (RACE/RTF/CRISP/FABRICâ€¦), **reasoning techniques** (CoT/ToT/ReAct), and **sound practices** (constraints, examples, iteration). Use simple frameworks for speed, and stricter ones when accuracy and reproducibility matter.
